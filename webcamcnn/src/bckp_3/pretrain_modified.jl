# projeto: webcamcnn
# file: webcamcnn/src/pretrain_modified.jl


# projeto: webcamcnn
# file: webcamcnn/src/pretrain_modified_with_visualization.jl

# Vers√£o modificada do pretrain_modified.jl com suporte a visualiza√ß√µes de camadas

using Flux
using Statistics
using Random
using JLD2
using Dates

include("core.jl")
include("weights_manager.jl")
include("layer_visualization.jl")  # Nova funcionalidade
using .CNNCheckinCore

# Constante para o arquivo de pesos
const WEIGHTS_TOML_PATH = "model_weights.toml"

# Pre-training function com visualiza√ß√µes integradas
function pretrain_model_with_visualizations(model, train_data, val_data, epochs, learning_rate, 
                                          person_names::Vector{String}; 
                                          save_viz_every::Int = 5)
    println("üöÄ Iniciando pr√©-treino com visualiza√ß√µes de camadas...")
    
    optimizer = ADAM(learning_rate, (0.9, 0.999), 1e-8)
    opt_state = Flux.setup(optimizer, model)
    
    train_losses = Float64[]
    val_accuracies = Float64[]
    best_val_acc = 0.0
    best_epoch = 0
    patience_counter = 0
    patience_limit = 10
    
    visualization_paths = String[]  # Armazenar caminhos das visualiza√ß√µes
    
    for epoch in 1:epochs
        epoch_loss = 0.0
        num_batches = 0
        
        println("\nüìä √âpoca $epoch/$epochs")
        
        # Training phase
        for (x, y) in train_data
            try
                loss, grads = Flux.withgradient(model) do m
                    ≈∑ = m(x)
                    Flux.logitcrossentropy(≈∑, y)
                end
                Flux.update!(opt_state, model, grads[1])
                epoch_loss += loss
                num_batches += 1
            catch e
                println("‚ùå Erro no treinamento do batch: $e")
                continue
            end
        end
        
        avg_loss = epoch_loss / num_batches
        push!(train_losses, avg_loss)
        
        # Validation phase
        val_acc = pretrain_accuracy(model, val_data)
        push!(val_accuracies, val_acc)
        
        println("Epoch $epoch/$epochs - Loss: $(round(avg_loss, digits=6)) - Val Acc: $(round(val_acc*100, digits=2))%")
        
        # Salvar visualiza√ß√µes em √©pocas espec√≠ficas
        if epoch % save_viz_every == 0 || epoch == 1 || epoch == epochs
            println("üé® Gerando visualiza√ß√µes para √©poca $epoch...")
            viz_path = add_visualization_to_training(model, train_data, person_names, epoch, 1)
            if viz_path !== nothing
                push!(visualization_paths, viz_path)
                println("‚úÖ Visualiza√ß√µes salvas em: $(basename(viz_path))")
            end
        end
        
        # Early stopping
        if val_acc > best_val_acc
            best_val_acc = val_acc
            best_epoch = epoch
            patience_counter = 0
            println("üèÜ Nova melhor acur√°cia: $(round(best_val_acc*100, digits=2))%")
        else
            patience_counter += 1
            if patience_counter >= patience_limit
                println("‚èπÔ∏è Early stopping na √©poca $epoch (paci√™ncia esgotada)")
                break
            end
        end
        
        # Mostrar progresso
        progress = epoch / epochs * 100
        println("üìà Progresso: $(round(progress, digits=1))% - Melhor √©poca: $best_epoch")
    end
    
    # Gerar visualiza√ß√£o final se n√£o foi gerada na √∫ltima √©poca
    if epochs % save_viz_every != 0
        println("üé® Gerando visualiza√ß√µes finais...")
        final_viz_path = generate_training_visualizations(model, train_data, person_names)
        push!(visualization_paths, final_viz_path)
    end
    
    return train_losses, val_accuracies, best_val_acc, best_epoch, visualization_paths
end

# Calculate accuracy (mesmo que antes)
function pretrain_accuracy(model, data_loader)
    correct = 0
    total = 0
    for (x, y) in data_loader
        try
            ≈∑ = softmax(model(x))
            pred = Flux.onecold(≈∑)
            true_labels = Flux.onecold(y)
            correct += sum(pred .== true_labels)
            total += length(true_labels)
        catch e
            println("‚ùå Erro calculando acur√°cia: $e")
            continue
        end
    end
    return total > 0 ? correct / total : 0.0
end

# Load initial training data (mesmo que antes)
function load_pretrain_data(data_path::String; use_augmentation::Bool = true)
    println("üìÇ Carregando dados de pr√©-treino...")
    
    if !isdir(data_path)
        error("Diret√≥rio $data_path n√£o encontrado!")
    end
    
    person_images = Dict{String, Vector{Array{Float32, 3}}}()
    image_extensions = [".jpg", ".jpeg", ".png", ".bmp", ".tiff"]
    
    for filename in readdir(data_path)
        file_ext = lowercase(splitext(filename)[2])
        if file_ext in image_extensions
            img_path = joinpath(data_path, filename)
            if !CNNCheckinCore.validate_image_file(img_path)
                continue
            end
            
            person_name = CNNCheckinCore.extract_person_name(filename)
            img_arrays = CNNCheckinCore.preprocess_image(img_path; augment=use_augmentation)
            
            if img_arrays !== nothing
                if !haskey(person_images, person_name)
                    person_images[person_name] = Vector{Array{Float32, 3}}()
                end
                for img_array in img_arrays
                    push!(person_images[person_name], img_array)
                end
                total_imgs = use_augmentation ? length(img_arrays) : 1
                println("‚úÖ Carregado: $filename -> $person_name ($total_imgs varia√ß√µes)")
            else
                println("‚ùå Falha ao carregar: $filename")
            end
        end
    end
    
    people_data = Vector{CNNCheckinCore.PersonData}()
    person_names = sort(collect(keys(person_images)))
    
    # Create person data with proper indexing
    for (idx, person_name) in enumerate(person_names)
        images = person_images[person_name]
        if length(images) > 0
            push!(people_data, CNNCheckinCore.PersonData(person_name, images, idx, false))
            println("üë§ Pessoa: $person_name - $(length(images)) imagens (Label: $idx)")
        end
    end
    
    return people_data, person_names
end

# Create balanced datasets (mesmo que antes)
function create_pretrain_datasets(people_data::Vector{CNNCheckinCore.PersonData}, split_ratio::Float64 = 0.8)
    println("üîÑ Criando datasets de treino e valida√ß√£o...")
    
    train_images = Vector{Array{Float32, 3}}()
    train_labels = Vector{Int}()
    val_images = Vector{Array{Float32, 3}}()
    val_labels = Vector{Int}()
    
    for person in people_data
        n_imgs = length(person.images)
        n_train = max(1, Int(floor(n_imgs * split_ratio)))
        indices = randperm(n_imgs)
        
        for i in 1:n_train
            push!(train_images, person.images[indices[i]])
            push!(train_labels, person.label)
        end
        
        for i in (n_train+1):n_imgs
            push!(val_images, person.images[indices[i]])
            push!(val_labels, person.label)
        end
        
        println("   - $(person.name): $n_train treino, $(n_imgs - n_train) valida√ß√£o")
    end
    
    println("üìä Dataset criado:")
    println("   - Treino: $(length(train_images)) imagens")
    println("   - Valida√ß√£o: $(length(val_images)) imagens")
    
    return (train_images, train_labels), (val_images, val_labels)
end

# Create training batches (mesmo que antes)
function create_pretrain_batches(images, labels, batch_size)
    batches = []
    n_samples = length(images)
    if n_samples == 0
        return batches
    end
    
    unique_labels = unique(labels)
    min_label = minimum(unique_labels)
    max_label = maximum(unique_labels)
    label_range = min_label:max_label
    
    println("üè∑Ô∏è Labels √∫nicos: $unique_labels")
    println("üè∑Ô∏è Range de labels: $label_range")
    
    for i in 1:batch_size:n_samples
        end_idx = min(i + batch_size - 1, n_samples)
        batch_images = images[i:end_idx]
        batch_labels = labels[i:end_idx]
        batch_tensor = cat(batch_images..., dims=4)
        
        try
            batch_labels_onehot = Flux.onehotbatch(batch_labels, label_range)
            push!(batches, (batch_tensor, batch_labels_onehot))
            println("   üì¶ Batch $(div(i-1, batch_size)+1): $(length(batch_labels)) amostras")
        catch e
            println("‚ùå Erro criando batch $i-$end_idx: $e")
            continue
        end
    end
    
    return batches
end

# CNN architecture (mesmo que antes)
function create_pretrain_cnn_model(num_classes::Int, input_size::Tuple{Int, Int} = CNNCheckinCore.IMG_SIZE)
    # Calculate final feature size after convolutions and pooling
    final_size = div(div(div(div(input_size[1], 2), 2), 2), 2)
    final_features = 256 * final_size * final_size
    
    return Chain(
        # Feature extraction layers
        Conv((3, 3), 3 => 64, relu, pad=1),
        BatchNorm(64),
        Dropout(0.1),
        MaxPool((2, 2)),
        
        Conv((3, 3), 64 => 128, relu, pad=1),
        BatchNorm(128),
        Dropout(0.1),
        MaxPool((2, 2)),
        
        Conv((3, 3), 128 => 256, relu, pad=1),
        BatchNorm(256),
        Dropout(0.15),
        MaxPool((2, 2)),
        
        Conv((3, 3), 256 => 256, relu, pad=1),
        BatchNorm(256),
        Dropout(0.15),
        MaxPool((2, 2)),
        
        # Classifier layers
        Flux.flatten,
        Dense(final_features, 512, relu),
        Dropout(0.4),
        Dense(512, 256, relu),
        Dropout(0.3),
        Dense(256, num_classes)
    )
end

# Main pre-training command com visualiza√ß√µes
function pretrain_command_with_visualizations(save_viz_every::Int = 5)
    println("\nüß† EXECUTANDO PR√â-TREINAMENTO COM VISUALIZA√á√ïES DE CAMADAS")
    println("=" ^ 60)
    
    start_time = time()
    
    try
        # Load pre-training data
        people_data, person_names = load_pretrain_data(CNNCheckinCore.TRAIN_DATA_PATH; use_augmentation=true)
        if length(people_data) == 0
            error("Nenhum dado de treino encontrado!")
        end
        
        num_classes = length(person_names)
        println("üë• Total de pessoas: $num_classes")
        total_images = sum(length(person.images) for person in people_data)
        println("üì∏ Total de imagens (com augmenta√ß√£o): $total_images")
        
        # Preparar estrutura de visualiza√ß√µes
        println("üé® Preparando sistema de visualiza√ß√µes...")
        create_visualization_directories(VIZ_OUTPUT_PATH, person_names)
        
        # Verificar se j√° existem treinamentos anteriores
        if isfile(WEIGHTS_TOML_PATH)
            println("\nüìö Treinamentos anteriores encontrados:")
            list_saved_trainings(WEIGHTS_TOML_PATH)
            println()
        else
            println("\nüÜï Primeiro treinamento - criando arquivo de pesos")
        end
        
        # Create datasets and batches
        (train_images, train_labels), (val_images, val_labels) = create_pretrain_datasets(people_data)
        train_batches = create_pretrain_batches(train_images, train_labels, CNNCheckinCore.BATCH_SIZE)
        val_batches = create_pretrain_batches(val_images, val_labels, CNNCheckinCore.BATCH_SIZE)
        
        if length(train_batches) == 0
            error("N√£o foi poss√≠vel criar batches de treino!")
        end
        
        # Create and train model
        println("üóÉÔ∏è Criando modelo CNN...")
        model = create_pretrain_cnn_model(num_classes)
        
        # Executar treinamento com visualiza√ß√µes
        train_losses, val_accuracies, best_val_acc, best_epoch, viz_paths = pretrain_model_with_visualizations(
            model, train_batches, val_batches, 
            CNNCheckinCore.PRETRAIN_EPOCHS, 
            CNNCheckinCore.LEARNING_RATE,
            person_names;
            save_viz_every = save_viz_every
        )
        
        end_time = time()
        duration_minutes = (end_time - start_time) / 60
        
        # Prepare training info
        training_info = Dict(
            "epochs_trained" => length(val_accuracies),
            "final_accuracy" => best_val_acc,
            "best_epoch" => best_epoch,
            "total_training_images" => length(train_images),
            "total_validation_images" => length(val_images),
            "augmentation_used" => true,
            "duration_minutes" => duration_minutes,
            "model_architecture" => "CNN_FaceRecognition_v1",
            "learning_rate" => CNNCheckinCore.LEARNING_RATE,
            "batch_size" => CNNCheckinCore.BATCH_SIZE,
            "visualization_paths" => viz_paths  # Incluir caminhos das visualiza√ß√µes
        )
        
        println("\nüéâ Pr√©-treino conclu√≠do!")
        println("üìä Resultados:")
        println("   - Melhor acur√°cia: $(round(best_val_acc*100, digits=2))% (√âpoca $best_epoch)")
        println("   - Epochs treinadas: $(training_info["epochs_trained"])/$(CNNCheckinCore.PRETRAIN_EPOCHS)")
        println("   - Dura√ß√£o: $(round(duration_minutes, digits=1)) minutos")
        println("   - Visualiza√ß√µes geradas: $(length(viz_paths)) conjuntos")
        
        # Mostrar caminhos das visualiza√ß√µes
        if !isempty(viz_paths)
            println("\nüé® Visualiza√ß√µes salvas em:")
            for viz_path in viz_paths
                println("   - $(basename(viz_path))")
            end
        end

        # Save model and configuration with TOML support
        success = save_pretrained_model_with_toml(model, person_names, CNNCheckinCore.MODEL_PATH, 
                                                 CNNCheckinCore.CONFIG_PATH, training_info)

        if success
            println("\n‚úÖ Sistema pr√©-treinado salvo com sucesso!")
            println("\nüìÅ Arquivos gerados:")
            println("   - Configura√ß√£o: $(CNNCheckinCore.CONFIG_PATH)")
            println("   - Modelo JLD2: $(CNNCheckinCore.MODEL_PATH)")
            println("   - Dados TOML: $(CNNCheckinCore.MODEL_DATA_TOML_PATH)")
            println("   - Pesos TOML: $WEIGHTS_TOML_PATH")
            
            # Criar relat√≥rio de visualiza√ß√µes
            if !isempty(viz_paths)
                create_training_visualization_report(viz_paths, person_names, training_info)
            end
            
            # Mostrar estat√≠sticas dos arquivos de peso
            println("\nüìà Resumo dos Treinamentos:")
            list_saved_trainings(WEIGHTS_TOML_PATH)
        else
            println("‚ùå Modelo treinado mas alguns arquivos falharam ao salvar")
        end

        return success

    catch e
        println("‚ùå Erro durante pr√©-treino: $e")
        return false
    end
end

# Fun√ß√£o para criar relat√≥rio das visualiza√ß√µes
function create_training_visualization_report(viz_paths::Vector{String}, 
                                            person_names::Vector{String}, 
                                            training_info::Dict)
    println("üìã Criando relat√≥rio das visualiza√ß√µes...")
    
    timestamp = Dates.format(now(), "yyyymmdd_HHMMSS")
    report_path = joinpath(VIZ_OUTPUT_PATH, "training_report_$timestamp.md")
    
    report_content = """
# Relat√≥rio de Treinamento com Visualiza√ß√µes

**Data do Treinamento:** $(Dates.format(now(), "dd/mm/yyyy HH:MM:SS"))
**Dura√ß√£o:** $(round(training_info["duration_minutes"], digits=1)) minutos
**Melhor Acur√°cia:** $(round(training_info["final_accuracy"]*100, digits=2))% (√âpoca $(training_info["best_epoch"]))

## Configura√ß√µes do Treinamento
- **Arquitetura:** $(training_info["model_architecture"])
- **√âpocas Treinadas:** $(training_info["epochs_trained"])
- **Learning Rate:** $(training_info["learning_rate"])
- **Batch Size:** $(training_info["batch_size"])
- **Augmenta√ß√£o:** $(training_info["augmentation_used"] ? "Sim" : "N√£o")

## Dataset
- **Pessoas:** $(length(person_names))
- **Imagens de Treino:** $(training_info["total_training_images"])
- **Imagens de Valida√ß√£o:** $(training_info["total_validation_images"])

### Pessoas Inclu√≠das:
$(join(["- $name" for name in person_names], "\n"))

## Visualiza√ß√µes Geradas
$(join(["- $(basename(path))" for path in viz_paths], "\n"))

## Como Interpretar as Visualiza√ß√µes

### Camadas Convolucionais (Conv):
1. **Camada 1-2:** Detectam bordas, linhas e texturas b√°sicas
2. **Camada 3-4:** Combinam caracter√≠sticas b√°sicas em padr√µes mais complexos
3. **Camadas Finais:** Detectam caracter√≠sticas espec√≠ficas de faces

### Filtros vs Ativa√ß√µes:
- **Filtros:** Mostram quais padr√µes cada filtro "procura"
- **Ativa√ß√µes:** Mostram como a imagem √© "vista" ap√≥s passar pela camada

### Indicadores de Qualidade:
- ‚úÖ **Bom:** Filtros diversos, ativa√ß√µes claras e diferenciadas
- ‚ö†Ô∏è **Aten√ß√£o:** Filtros muito similares ou ativa√ß√µes uniformes
- ‚ùå **Problema:** Filtros "mortos" (todos zeros) ou ativa√ß√µes ca√≥ticas

## An√°lise por Camada

### Layer 1 (Conv 3x3, 3‚Üí64):
- Deve mostrar detectores de bordas em diferentes orienta√ß√µes
- Ativa√ß√µes devem real√ßar contornos faciais

### Layer 2 (Conv 3x3, 64‚Üí128):  
- Filtros devem combinar bordas em padr√µes mais complexos
- Ativa√ß√µes come√ßam a mostrar caracter√≠sticas faciais b√°sicas

### Layer 3 (Conv 3x3, 128‚Üí256):
- Detectores de caracter√≠sticas faciais mais espec√≠ficas
- Ativa√ß√µes mostram regi√µes importantes para reconhecimento

### Layer 4 (Conv 3x3, 256‚Üí256):
- Caracter√≠sticas muito espec√≠ficas para cada pessoa
- Ativa√ß√µes altamente seletivas

### Layers Dense:
- Representa√ß√£o vetorial das caracter√≠sticas
- Visualizada como mapas de calor da "import√¢ncia"

## Pr√≥ximos Passos
1. Compare visualiza√ß√µes entre diferentes √©pocas
2. Analise se os filtros est√£o aprendendo caracter√≠sticas relevantes
3. Identifique poss√≠veis overfitting observando ativa√ß√µes muito espec√≠ficas
4. Use as visualiza√ß√µes para ajustar hiperpar√¢metros se necess√°rio

## Arquivos de Refer√™ncia
- **Modelo JLD2:** $(CNNCheckinCore.MODEL_PATH)
- **Configura√ß√£o:** $(CNNCheckinCore.CONFIG_PATH)
- **Pesos TOML:** $WEIGHTS_TOML_PATH

---
*Relat√≥rio gerado automaticamente pelo sistema CNN Checkin*
"""
    
    try
        open(report_path, "w") do f
            write(f, report_content)
        end
        println("‚úÖ Relat√≥rio salvo em: $report_path")
        return report_path
    catch e
        println("‚ùå Erro ao criar relat√≥rio: $e")
        return nothing
    end
end

# Save model with TOML support (mesmo que antes)
function save_pretrained_model_with_toml(model, person_names, model_path, config_path, training_info)
    # Salvar modelo em JLD2
    JLD2.save(model_path, "model", model, "person_names", person_names)
    
    # Salvar config com prefixo do m√≥dulo correto
    config = CNNCheckinCore.load_config(config_path)
    config["training"]["epochs_trained"] = training_info["epochs_trained"]
    config["training"]["final_accuracy"] = training_info["final_accuracy"]
    config["training"]["best_epoch"] = training_info["best_epoch"]
    config["data"]["person_names"] = person_names
    CNNCheckinCore.save_config(config, config_path)
    
    # Salvar dados TOML
    CNNCheckinCore.save_model_data_toml(model, person_names, CNNCheckinCore.MODEL_DATA_TOML_PATH)
    
    # Salvar pesos TOML
    save_pretrained_weights_toml(model, person_names, training_info, WEIGHTS_TOML_PATH)
    
    return true
end

# Menu para gerenciar visualiza√ß√µes
function visualization_management_menu()
    while true
        println("\nüé® MENU DE GERENCIAMENTO DE VISUALIZA√á√ïES")
        println("=" * 50)
        println("1 - Executar treinamento com visualiza√ß√µes")
        println("2 - Gerar visualiza√ß√µes de modelo existente")
        println("3 - Comparar visualiza√ß√µes entre treinamentos")
        println("4 - Listar visualiza√ß√µes dispon√≠veis")
        println("5 - Limpar visualiza√ß√µes antigas")
        println("6 - Voltar")
        
        print("Escolha uma op√ß√£o: ")
        choice = strip(readline())
        
        if choice == "1"
            print("Salvar visualiza√ß√µes a cada quantas √©pocas? (padr√£o: 5): ")
            freq_input = readline()
            save_freq = isempty(freq_input) ? 5 : parse(Int, freq_input)
            return pretrain_command_with_visualizations(save_freq)
            
        elseif choice == "2"
            println("üîç Fun√ß√£o para gerar visualiza√ß√µes de modelo existente")
            println("   (Requer implementa√ß√£o adicional para carregar modelo JLD2)")
            
        elseif choice == "3"
            println("üìä Comparar visualiza√ß√µes entre treinamentos")
            viz_dirs = []
            if isdir(VIZ_OUTPUT_PATH)
                viz_dirs = filter(isdir, [joinpath(VIZ_OUTPUT_PATH, d) for d in readdir(VIZ_OUTPUT_PATH)])
            end
            
            if length(viz_dirs) < 2
                println("‚ùå S√£o necess√°rias pelo menos 2 visualiza√ß√µes para compara√ß√£o")
            else
                println("Diret√≥rios dispon√≠veis:")
                for (i, dir) in enumerate(viz_dirs)
                    println("   $i - $(basename(dir))")
                end
                
                print("Escolha o primeiro diret√≥rio (n√∫mero): ")
                idx1 = parse(Int, readline())
                print("Escolha o segundo diret√≥rio (n√∫mero): ")
                idx2 = parse(Int, readline())
                
                if 1 <= idx1 <= length(viz_dirs) && 1 <= idx2 <= length(viz_dirs)
                    compare_layer_visualizations(viz_dirs[idx1], viz_dirs[idx2])
                end
            end
            
        elseif choice == "4"
            println("üìã Visualiza√ß√µes Dispon√≠veis:")
            if isdir(VIZ_OUTPUT_PATH)
                for dir in readdir(VIZ_OUTPUT_PATH)
                    dir_path = joinpath(VIZ_OUTPUT_PATH, dir)
                    if isdir(dir_path)
                        println("   üìÅ $dir")
                        # Mostrar pessoas dentro do diret√≥rio
                        subdirs = filter(isdir, [joinpath(dir_path, d) for d in readdir(dir_path)])
                        if !isempty(subdirs)
                            println("      üë• Pessoas: $(join([basename(d) for d in subdirs[1:min(3, end)]], ", "))")
                        end
                    end
                end
            else
                println("   üì≠ Nenhuma visualiza√ß√£o encontrada")
            end
            
        elseif choice == "5"
            println("üßπ Limpeza de Visualiza√ß√µes Antigas")
            if isdir(VIZ_OUTPUT_PATH)
                viz_dirs = filter(isdir, [joinpath(VIZ_OUTPUT_PATH, d) for d in readdir(VIZ_OUTPUT_PATH)])
                if length(viz_dirs) > 3
                    print("Manter quantas visualiza√ß√µes mais recentes? (padr√£o: 3): ")
                    keep_n = readline()
                    keep_n = isempty(keep_n) ? 3 : parse(Int, keep_n)
                    
                    # Ordenar por data de modifica√ß√£o
                    sort!(viz_dirs, by=d -> stat(d).mtime, rev=true)
                    
                    # Remover antigas
                    for old_dir in viz_dirs[keep_n+1:end]
                        try
                            rm(old_dir, recursive=true)
                            println("üóëÔ∏è Removido: $(basename(old_dir))")
                        catch e
                            println("‚ùå Erro ao remover $(basename(old_dir)): $e")
                        end
                    end
                    
                    println("‚úÖ Limpeza conclu√≠da. Mantidas $(min(keep_n, length(viz_dirs))) visualiza√ß√µes.")
                else
                    println("‚ÑπÔ∏è Poucas visualiza√ß√µes para limpeza ($(length(viz_dirs)) encontradas)")
                end
            else
                println("üì≠ Diret√≥rio de visualiza√ß√µes n√£o existe")
            end
            
        elseif choice == "6"
            return false
            
        else
            println("‚ùå Op√ß√£o inv√°lida!")
        end
        
        println("\nPressione Enter para continuar...")
        readline()
    end
end

# Export functions
export pretrain_command_with_visualizations, visualization_management_menu,
       create_training_visualization_report